{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkOYVlvXkWbLuKOM2nL4O+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PraeJi/Python-Practice/blob/master/3_02_tf_neuralnetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks"
      ],
      "metadata": {
        "id": "f2xdd1G88dCG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTSYxeOj8WeP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "\n",
        "# define training example\n",
        "X = tf.constant([[0.0, 0.0],\n",
        "                 [0.0, 0.1],\n",
        "                 [1.0, 0.0],\n",
        "                 [1.0, 1.0]])\n",
        "y = tf.constant([[0.0],\n",
        "                 [1.0],\n",
        "                 [1.0],\n",
        "                 [0.0]])\n",
        "\n",
        "# define layer 1\n",
        "W1 = tf.Variable(tf.random.normal((2, 2))) # weight for layer 1\n",
        "b1 = tf.Variable(tf.random.normal((1, 2))) # bias for layer 1\n",
        "\n",
        "# define layer 2\n",
        "W2 = tf.Variable(tf.random.normal((2, 1)))\n",
        "b2 = tf.Variable(tf.random.normal((1, 1)))\n",
        "\n",
        "eta = 1\n",
        "\n",
        "for i in range(600):\n",
        "  # define output and loss\n",
        "  with tf.GradientTape() as tape:\n",
        "    a1 = tf.nn.sigmoid(tf.matmul(X, W1) + b1)\n",
        "    a2 = tf.nn.sigmoid(tf.matmul(a1, W2) + b2)\n",
        "    L = tf.reduce_sum(-(y*tf.math.log(a2) + (1-y)*tf.math.log(1-a2)))/n # L represent loss function\n",
        "\n",
        "  # calculate gradiente\n",
        "  [gw1, gb1, gw2, gb2] = tape.gradient(L, [W1, b1, W2, b2])\n",
        "\n",
        "  # update w qnd b\n",
        "  W2.assign_add(-eta*gw2)\n",
        "  b2.assign_add(-eta*gb2)\n",
        "  W1.assign_add(-eta*gw1)\n",
        "  b1.assign_add(-eta*gb1)\n",
        "\n",
        "# calculate y_hat\n",
        "a1 = tf.math.sigmoid(tf.matmul(X, W1) + b1)\n",
        "a2 = tf.math.sigmoid(tf.matmul(a1, W2) + b2)\n",
        "y_hat = tf.round(a2)\n",
        "print(\"Predicted output = \")\n",
        "tf.print(y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSg2cFy48l2a",
        "outputId": "e6f11b3f-287e-4cf4-a3df-e2f5e4a6c41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output = \n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras API"
      ],
      "metadata": {
        "id": "RtIvr6a4FHIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "\n",
        "# define training example\n",
        "X = tf.constant([[0.0, 0.0],\n",
        "                 [0.0, 0.1],\n",
        "                 [1.0, 0.0],\n",
        "                 [1.0, 1.0]])\n",
        "y = tf.constant([[0.0],\n",
        "                 [1.0],\n",
        "                 [1.0],\n",
        "                 [0.0]])\n",
        "\n",
        "# define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(2,)), # the input layer has 2 components\n",
        "    tf.keras.layers.Dense(8, activation='sigmoid'), # first hidden layer has 2 units (or neural network) inside\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') # the output layer has 1 units\n",
        "])\n",
        "\n",
        "# Note: - Dense mean this is the basic \"fully connected layer\"\n",
        "#       - fully connected layer mean all the input are completly connected to all of unit in this layer\n",
        "\n",
        "# define the training algorithm and loss function\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1.5),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(X, y, epochs=200, batch_size=1, shuffle=True)\n",
        "\n",
        "# predict\n",
        "a = model.predict(X)\n",
        "y_hat = tf.round(a)\n",
        "print(y_hat)\n",
        "\n",
        "# evaluate the model\n",
        "model.evaluate(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6quq7nvBa82",
        "outputId": "061a89e2-ca35-4b70-ec9e-281d9e67f2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 1.0759  \n",
            "Epoch 2/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4667 - loss: 1.1612 \n",
            "Epoch 3/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 1.4436 \n",
            "Epoch 4/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 1.3160 \n",
            "Epoch 5/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.9312     \n",
            "Epoch 6/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4667 - loss: 0.8901 \n",
            "Epoch 7/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6452 \n",
            "Epoch 8/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 1.2325 \n",
            "Epoch 9/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6333 - loss: 0.7957\n",
            "Epoch 10/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4667 - loss: 0.8161 \n",
            "Epoch 11/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3667 - loss: 0.8249    \n",
            "Epoch 12/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4667 - loss: 0.8595\n",
            "Epoch 13/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3667 - loss: 0.8197    \n",
            "Epoch 14/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6333 - loss: 0.8246 \n",
            "Epoch 15/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1667 - loss: 0.9904     \n",
            "Epoch 16/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1667 - loss: 0.8821     \n",
            "Epoch 17/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4667 - loss: 0.7097 \n",
            "Epoch 18/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.6121 \n",
            "Epoch 19/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4667 - loss: 0.6522 \n",
            "Epoch 20/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1667 - loss: 0.9506     \n",
            "Epoch 21/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.6207 \n",
            "Epoch 22/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1667 - loss: 0.8223     \n",
            "Epoch 23/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.5693 \n",
            "Epoch 24/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.4950 \n",
            "Epoch 25/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2667 - loss: 0.7790     \n",
            "Epoch 26/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6007 \n",
            "Epoch 27/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.7827 \n",
            "Epoch 28/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2667 - loss: 0.8809     \n",
            "Epoch 29/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.6155 \n",
            "Epoch 30/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4230 \n",
            "Epoch 31/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1667 - loss: 0.8441    \n",
            "Epoch 32/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9000 - loss: 0.3924\n",
            "Epoch 33/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6333 - loss: 0.6476 \n",
            "Epoch 34/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.5535 \n",
            "Epoch 35/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5667 - loss: 0.6522 \n",
            "Epoch 36/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4431 \n",
            "Epoch 37/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3774 \n",
            "Epoch 38/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.5803 \n",
            "Epoch 39/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.7143     \n",
            "Epoch 40/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.4872 \n",
            "Epoch 41/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.5563 \n",
            "Epoch 42/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.5665 \n",
            "Epoch 43/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.6102     \n",
            "Epoch 44/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6698 \n",
            "Epoch 45/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7840     \n",
            "Epoch 46/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.2982 \n",
            "Epoch 47/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.3527 \n",
            "Epoch 48/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4333 - loss: 0.5834    \n",
            "Epoch 49/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.4609 \n",
            "Epoch 50/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.7770     \n",
            "Epoch 51/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4333 - loss: 0.6500     \n",
            "Epoch 52/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6582 \n",
            "Epoch 53/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.5839     \n",
            "Epoch 54/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.3075 \n",
            "Epoch 55/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.6761     \n",
            "Epoch 56/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4333 - loss: 0.5769     \n",
            "Epoch 57/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.4199 \n",
            "Epoch 58/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2906 \n",
            "Epoch 59/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.4669 \n",
            "Epoch 60/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.6714     \n",
            "Epoch 61/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7898     \n",
            "Epoch 62/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3942 \n",
            "Epoch 63/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.2849 \n",
            "Epoch 64/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.4189 \n",
            "Epoch 65/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2667 - loss: 0.7522     \n",
            "Epoch 66/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.4983 \n",
            "Epoch 67/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.6008     \n",
            "Epoch 68/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8333 - loss: 0.5043 \n",
            "Epoch 69/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8333 - loss: 0.4026 \n",
            "Epoch 70/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6493 \n",
            "Epoch 71/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5216 \n",
            "Epoch 72/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4187 \n",
            "Epoch 73/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5010 \n",
            "Epoch 74/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7072     \n",
            "Epoch 75/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5027 \n",
            "Epoch 76/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.3049 \n",
            "Epoch 77/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.3629 \n",
            "Epoch 78/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2497 \n",
            "Epoch 79/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.5800     \n",
            "Epoch 80/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.4459 \n",
            "Epoch 81/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.5598     \n",
            "Epoch 82/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2667 - loss: 0.7597     \n",
            "Epoch 83/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.6461     \n",
            "Epoch 84/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7500     \n",
            "Epoch 85/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6333 - loss: 0.3763 \n",
            "Epoch 86/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.6227\n",
            "Epoch 87/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.4813     \n",
            "Epoch 88/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.3081 \n",
            "Epoch 89/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.2482 \n",
            "Epoch 90/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2515 \n",
            "Epoch 91/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.6954     \n",
            "Epoch 92/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.4887 \n",
            "Epoch 93/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.2626 \n",
            "Epoch 94/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6252 \n",
            "Epoch 95/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4333 - loss: 0.4940     \n",
            "Epoch 96/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.3876 \n",
            "Epoch 97/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4248 \n",
            "Epoch 98/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4093 \n",
            "Epoch 99/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.4179 \n",
            "Epoch 100/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4044 \n",
            "Epoch 101/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2427 \n",
            "Epoch 102/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4333 - loss: 0.5054     \n",
            "Epoch 103/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2667 - loss: 0.7249     \n",
            "Epoch 104/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2378 \n",
            "Epoch 105/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3095 \n",
            "Epoch 106/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3667 - loss: 0.5852    \n",
            "Epoch 107/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.2826 \n",
            "Epoch 108/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.4213 \n",
            "Epoch 109/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.6957     \n",
            "Epoch 110/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6189 \n",
            "Epoch 111/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.2552 \n",
            "Epoch 112/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.3528 \n",
            "Epoch 113/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.4344 \n",
            "Epoch 114/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.4377 \n",
            "Epoch 115/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.3686 \n",
            "Epoch 116/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.2735 \n",
            "Epoch 117/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6107 \n",
            "Epoch 118/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2446 \n",
            "Epoch 119/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.4941 \n",
            "Epoch 120/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6304 \n",
            "Epoch 121/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.2959 \n",
            "Epoch 122/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.5755     \n",
            "Epoch 123/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3926 \n",
            "Epoch 124/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.2391 \n",
            "Epoch 125/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.4986\n",
            "Epoch 126/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5667 - loss: 0.4081\n",
            "Epoch 127/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2332 \n",
            "Epoch 128/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.4034 \n",
            "Epoch 129/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2385 \n",
            "Epoch 130/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6333 - loss: 0.3334 \n",
            "Epoch 131/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3907 \n",
            "Epoch 132/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.4891     \n",
            "Epoch 133/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.6026     \n",
            "Epoch 134/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.5433     \n",
            "Epoch 135/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6065 \n",
            "Epoch 136/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3052 \n",
            "Epoch 137/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.2551 \n",
            "Epoch 138/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6107 \n",
            "Epoch 139/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.2503\n",
            "Epoch 140/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9000 - loss: 0.3919\n",
            "Epoch 141/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5667 - loss: 0.4030\n",
            "Epoch 142/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3667 - loss: 0.5902    \n",
            "Epoch 143/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3667 - loss: 0.6113     \n",
            "Epoch 144/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9000 - loss: 0.2313 \n",
            "Epoch 145/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6333 - loss: 0.3256\n",
            "Epoch 146/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7333 - loss: 0.2601\n",
            "Epoch 147/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9000 - loss: 0.2822\n",
            "Epoch 148/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2667 - loss: 0.6617    \n",
            "Epoch 149/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4333 - loss: 0.5161     \n",
            "Epoch 150/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4333 - loss: 0.5440    \n",
            "Epoch 151/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3667 - loss: 0.6194    \n",
            "Epoch 152/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4333 - loss: 0.5494    \n",
            "Epoch 153/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8333 - loss: 0.3658\n",
            "Epoch 154/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8333 - loss: 0.5124\n",
            "Epoch 155/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7333 - loss: 0.6185\n",
            "Epoch 156/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2667 - loss: 0.6703    \n",
            "Epoch 157/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.2604\n",
            "Epoch 158/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9000 - loss: 0.2287 \n",
            "Epoch 159/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7333 - loss: 0.6323\n",
            "Epoch 160/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6333 - loss: 0.3341 \n",
            "Epoch 161/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.6055     \n",
            "Epoch 162/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.3668 \n",
            "Epoch 163/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.3867\n",
            "Epoch 164/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6333 - loss: 0.3333\n",
            "Epoch 165/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5667 - loss: 0.4216\n",
            "Epoch 166/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.3583 \n",
            "Epoch 167/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.2657 \n",
            "Epoch 168/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3667 - loss: 0.6182     \n",
            "Epoch 169/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7175     \n",
            "Epoch 170/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.6190     \n",
            "Epoch 171/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.2272 \n",
            "Epoch 172/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.3808 \n",
            "Epoch 173/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6167 \n",
            "Epoch 174/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.2471 \n",
            "Epoch 175/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.4761 \n",
            "Epoch 176/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.4802     \n",
            "Epoch 177/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.2584 \n",
            "Epoch 178/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6036 \n",
            "Epoch 179/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6316 \n",
            "Epoch 180/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.4982     \n",
            "Epoch 181/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.2600 \n",
            "Epoch 182/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5667 - loss: 0.4232\n",
            "Epoch 183/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9000 - loss: 0.2270\n",
            "Epoch 184/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2990  \n",
            "Epoch 185/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4015 \n",
            "Epoch 186/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.3272 \n",
            "Epoch 187/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8333 - loss: 0.4746 \n",
            "Epoch 188/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.3250 \n",
            "Epoch 189/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4333 - loss: 0.5226     \n",
            "Epoch 190/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.3682 \n",
            "Epoch 191/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5667 - loss: 0.3924 \n",
            "Epoch 192/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.3394 \n",
            "Epoch 193/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.2595 \n",
            "Epoch 194/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3667 - loss: 0.6109     \n",
            "Epoch 195/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2667 - loss: 0.7125     \n",
            "Epoch 196/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.2276 \n",
            "Epoch 197/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4308 \n",
            "Epoch 198/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.3703 \n",
            "Epoch 199/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.3765\n",
            "Epoch 200/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5667 - loss: 0.3993\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]], shape=(4, 1), dtype=float32)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.7500 - loss: 0.3633\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36329972743988037, 0.75]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = np.column_stack((X, y))\n",
        "np.save('xor.npy', D)"
      ],
      "metadata": {
        "id": "FyvTruKiQ0lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = np.load('xor.npy')\n",
        "X = D[:, :2]\n",
        "y = D[:, 2]"
      ],
      "metadata": {
        "id": "gPZHvYOYNBQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6mgTRrcoOkCu",
        "outputId": "c19b35fb-8c29-44d8-974c-04d5423eb2e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "* 0 or 1 output use \"sigmoid\"\n",
        "* -1 or 1 output use \"tanh\"\n",
        "* real or continuous output use \"linear\""
      ],
      "metadata": {
        "id": "d90UwBWoSb-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(2,)), # the input layer has 2 components\n",
        "    tf.keras.layers.Dense(8, activation='relu'), # first hidden layer has 2 units (or neural network) inside\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid') # the output layer has 1 units\n",
        "])\n",
        "\n",
        "# define the training algorithm and loss function\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(X, y, epochs=500, batch_size=8)\n",
        "\n",
        "# predict\n",
        "a = model.predict(X)\n",
        "y_hat = tf.round(a)\n",
        "print(y_hat)\n",
        "\n",
        "# evaluate the model\n",
        "model.evaluate(X, y)"
      ],
      "metadata": {
        "id": "tI8Dlcn2REMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_hat)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S2fLuMW4f2Bl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}