{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa7nJH2bVkg05EPqkyjxXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PraeJi/Python-Practice/blob/master/3_05_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "77vbFUDWUK5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sfm2oRU4UCZD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Cats vs Dogs dataset"
      ],
      "metadata": {
        "id": "eYDarFpTUT_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the \"cats vs dogs\" dataset using tensorflow_datasets\n",
        "# Split the dataset into 3 subsets:\n",
        "#   70% for training,\n",
        "#   15% for validation,\n",
        "#   15% for testing\n",
        "d_train, d_valid, d_test = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    split=[\"train[:70%]\", \"train[70%:85%]\", \"train[85%:100%]\"],\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "# Display the number of examples in each subset\n",
        "print(\"n_train = %d\" % tf.data.experimental.cardinality(d_train))\n",
        "print(\"n_valid = %d\" % tf.data.experimental.cardinality(d_valid))\n",
        "print(\"n_test = %d\" % tf.data.experimental.cardinality(d_test))"
      ],
      "metadata": {
        "id": "Wx8f0E5xUZZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess\n",
        "#\n",
        "# Resize each image into 64x64\n",
        "size = (64, 64)\n",
        "d_train = d_train.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "d_valid = d_valid.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "d_test = d_test.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "\n",
        "# Normalize the color values\n",
        "d_train = d_train.map(lambda x, y: (x / 255, y))\n",
        "d_valid = d_valid.map(lambda x, y: (x / 255, y))\n",
        "d_test = d_test.map(lambda x, y: (x / 255, y))\n",
        "\n",
        "# Set up batches\n",
        "batch_size = 32\n",
        "d_train = d_train.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "d_test = d_test.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "d_valid = d_valid.cache().batch(batch_size).prefetch(buffer_size=10)"
      ],
      "metadata": {
        "id": "C0po21VGV5E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the VGG16 model"
      ],
      "metadata": {
        "id": "snmGVO9RWzFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model and use it as the base model\n",
        "# Use the weights trained by the imagenent dataset\n",
        "base_model = tf.keras.applications.VGG16(weights='imagenet',\n",
        "                                         input_shape=(64, 64, 3),\n",
        "                                         include_top=False)"
      ],
      "metadata": {
        "id": "h2_KoWT7WywB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the classification part"
      ],
      "metadata": {
        "id": "nr4qiSJAXaPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the weight of VGG16\n",
        "base_model.trainable = False\n",
        "\n",
        "# Set up the classification part of the model\n",
        "inputs = tf.keras.Input(shape=(64, 64, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "x = tf.keras.layers.Dense(0.3)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu',\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(3e-4),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "73MTQes6XeAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the classification part"
      ],
      "metadata": {
        "id": "HvrtyRSVbbe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(d_train,\n",
        "          epochs=20,\n",
        "          batch_size=batch_size,\n",
        "          shuffle=True, validation_data=d_valid)\n",
        "\n",
        "# Evaluate the model using the test set\n",
        "model.evaluate(d_test, verbose=0)\n",
        "\n",
        "r = model.evaluate(d_test, verbose=0)\n",
        "print(f\"Test accuracy 1 = {r[1]:.4f}\")"
      ],
      "metadata": {
        "id": "DDzvoJzmbVaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning the model"
      ],
      "metadata": {
        "id": "2jyLmDYhcVfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tune the model\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "# The learning rate is set to a very small value\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-6),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the entire model\n",
        "model.fit(d_train, epochs=10, batch_size=batch_size, shuffle=True,\n",
        "          validation_data=d_valid)\n",
        "\n",
        "# Evaluate the model using the test set\n",
        "r = model.evaluate(d_test, verbose=0)\n",
        "print(f\"Test accuracy 2 = {r[1]:.4f}\")"
      ],
      "metadata": {
        "id": "7W9llLYMcVPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1, y_test1 = list(d_test)[0]"
      ],
      "metadata": {
        "id": "TNgcTHHKdUzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(X_test1[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xI841Chbde4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test1[0:2])\n",
        "tf.print(y_pred)\n",
        "tf.print(y_test1[0:2])"
      ],
      "metadata": {
        "id": "VE5t6BmQdocd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}